# Neural Networks for Implicit Representations-papers
Papers club from the AI team in D-ID  - this time Neural Networks for Implicit Representations

An implicit neural representations is a parameterization of a signal as a continuous function that maps the domain of the signal to the signal value, for example an image coordinate to the RGB value.

A really good explnantion on what are "Neural Networks for Implicit Representations" and why are they intresting can be found in [awesome-implicit-representations](https://github.com/vsitzmann/awesome-implicit-representations)

מועדון קריאת מאמרים שלנו - כל ההרצאות בעיברית
| Lecture | Paper / Resource | Year | Why is it interesting? | Asignee | Recording | Slides |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| Neural Networks for Implicit Representations of 3D Scenes |[Neural Networks for Implicit Representations of 3D Scenes](http://sibgrapi.sid.inpe.br/col/sid.inpe.br/sibgrapi/2021/09.11.20.09/doc/Tutorial_Sibgrapi_2021%20(2).pdf) | 2021 | <details><summary>read why</summary>Why and how we can represnt 3d scene using a neural netwrok</details> | [@amitay.nachmani](https://github.com/amitay.nachmani) | [zoom](zoom_link) () | [slides](google slides) |
| DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation |[DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation](https://arxiv.org/abs/1901.05103) | 2019 | <details><summary>read why</summary>Representing a scene using signed distance functions</details> | []() | [zoom](zoom_link) () | [slides](google slides) |
| Occupancy Networks: Learning 3D Reconstruction in Function Space |[Occupancy Networks: Learning 3D Reconstruction in Function Space](https://arxiv.org/abs/1812.03828) | 2019 | <details><summary>read why</summary>Occupancy networks implicitly represent the 3D surface as the continuous decision boundary of a deep neural network classifier</details> | []() | [zoom](zoom_link) () | [slides](google slides) |
| Implicit Neural Representations with Periodic Activation Functions AKA SIREN|[Implicit Neural Representations with Periodic Activation Functions](https://arxiv.org/abs/2006.09661) | 2020 | <details><summary>read why</summary>Sinusoidal representation networks or SIRENs, are ideally suited for representing complex natural signals and their derivatives</details> | []() | [zoom](zoom_link) () | [slides](google slides) |
| NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis|[NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis](https://arxiv.org/abs/2006.09661) | 2020 | <details><summary>read why</summary> The paper that started all the NERF madness</details> | [@TBH]() | [zoom](zoom_link) () | [slides](google slides) |
| Nerfies: Deformable Neural Radiance Fields |[Nerfies: Deformable Neural Radiance Fields](https://arxiv.org/abs/2011.12948) | 2021 | <details><summary>read why</summary>Photorealistically reconstructing deformable scenes using photos/videos captured casually from mobile phone</details> | []() | [zoom](zoom_link) () | [slides](google slides) |
| Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction |[Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction](https://arxiv.org/abs/2012.03065) | 2020 | <details><summary>read why</summary> Dynamic neural radiance fields for modeling the appearance and dynamics of a human face</details> | [@ganit.kupershmidt ](ganit) | [zoom](zoom_link) () | [slides](google slides) |
| Animatable Neural Radiance Fields from Monocular RGB Videos|[Animatable Neural Radiance Fields from Monocular RGB Videos](https://arxiv.org/abs/2106.13629) | 2021 | <details><summary>read why</summary>Creating full body avatars using NERF</details> | []() | [zoom](zoom_link) () | [slides](google slides) |
| Authentic Volumetric Avatars from a Phone Scan |[Authentic Volumetric Avatars from a Phone Scan](https://drive.google.com/file/d/1i4NJKAggS82wqMamCJ1OHRGgViuyoY6R/view) | 2022 | <details><summary>read why</summary>Creating an high resolution vavatar only from a cell phone video</details> | [@amitay.nachmani](https://github.com/amitay.nachmani) | [zoom](zoom_link) () | [slides](google slides) |
| ReLU Fields: The Little Non-linearity That Could |[ReLU Fields: The Little Non-linearity That Could](https://arxiv.org/abs/2205.10824) | 2022 | <details><summary>read why</summary>what is the smallest change to grid-based representations that allows for retaining the high fidelity result of MLPs while enabling fast reconstruction and rendering times</details> | []() | [zoom](zoom_link) () | [slides](google slides) |
