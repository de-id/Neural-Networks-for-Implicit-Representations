# Neural Networks for Implicit Representations-papers
Papers club from the AI team in D-ID  - this time Neural Networks for Implicit Representations

An implicit neural representations is a parameterization of a signal as a continuous function that maps the domain of the signal to the signal value, for example an float image coordinate to the RGB value.

A really good explnantion on what are "Neural Networks for Implicit Representations" and why are they intresting can be found in [awesome-implicit-representations](https://github.com/vsitzmann/awesome-implicit-representations)

[Neuralfields website](https://neuralfields.cs.brown.edu/index.html)

מועדון קריאת מאמרים שלנו - כל ההרצאות בעיברית
| Title | Paper / Resource | Year | Why is it interesting? | Asignee | Recording | Slides |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| Neural Fields in Visual Computing and Beyond |[Neural Fields in Visual Computing and Beyond](https://arxiv.org/pdf/2111.11426.pdf) | 2022 | <details><summary>read why</summary>Why and how we can represnt 3d scene using a neural netwrok</details> | [@amitay.nachmani](https://github.com/amitay.nachmani) | [zoom](https://us02web.zoom.us/rec/share/QD26LOm-xmp8OEmOkWkFFwPvhDx2nXcPdvxI8HkQO9bhQM8rxIt6faPj022EUSk.XPKEUa6z0qEd1cMo) (d0D9Yv$8) | [slides](https://docs.google.com/presentation/d/19m52ynBui7MK11ya6Zltr7II4-0BJCZf6_zwdrXZl0A/edit?usp=sharing) |
| DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation |[DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation](https://arxiv.org/abs/1901.05103) | 2019 | <details><summary>read why</summary>Representing a scene using signed distance functions</details> | [@matan.feldman](https://github.com/matan-feldman) | [zoom](https://us02web.zoom.us/rec/share/x7hPeb9d2qfwc1V6bFabdo1thMCeuJ_QzUY1D1Wq1XHRivtAOwDun0Z5t0eE-zGY.22-YO1ckzTksIdH1) (46RYCe*k) | [slides](https://docs.google.com/presentation/d/1czeQtcWgZzNrrsx_2HFXroAV0JqyHMZKJyUBbYAc0WQ/edit?usp=sharing) |
| Occupancy Networks: Learning 3D Reconstruction in Function Space |[Occupancy Networks: Learning 3D Reconstruction in Function Space](https://arxiv.org/abs/1812.03828) | 2019 | <details><summary>read why</summary>Occupancy networks implicitly represent the 3D surface as the continuous decision boundary of a deep neural network classifier</details> | [self-work]() | - | - |
| Implicit Neural Representations with Periodic Activation Functions AKA SIREN|[Implicit Neural Representations with Periodic Activation Functions](https://arxiv.org/abs/2006.09661) | 2020 | <details><summary>read why</summary>Sinusoidal representation networks or SIRENs, are ideally suited for representing complex natural signals and their derivatives</details> | [@matan.feldman](https://github.com/matan-feldman) | [zoom](https://us02web.zoom.us/rec/share/1HeFGpMhOPu0qZ_a_jdmYS6pvb6VGfm9rA0KexwFqXxAUIwoWIBMsOpcxr9X0cIZ.StUlt594g6fQy-mf) (T8Y6@^2N) | [slides](https://docs.google.com/presentation/d/15HhZ305OsXNPu9ZL3IzoekaLvcQuSkmJbzAQGU2X7cc/edit#slide=id.g1404a0c6356_0_9) |
| NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis|[NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis](https://arxiv.org/abs/2003.08934) | 2020 | <details><summary>read why</summary> The paper that started all the NERF madness</details> | [@TBH](https://github.com/talbenh) | [zoom](https://us02web.zoom.us/rec/share/7DTDIn2lDWJRqAv2x7HUTagQQdv-nrH_BAEbn9DpTtcYR-QXr47hXujDMwvr3lE.LkEMY0m5rpBzoktN)  (kdx=Zd0a) | [slides](https://docs.google.com/presentation/d/1_t6VICucYpkKEIJCA6M1WHBkDQQ1xvGj-HqCgWD__Rw/edit?usp=sharing) |
| Nerfies: Deformable Neural Radiance Fields |[Nerfies: Deformable Neural Radiance Fields](https://arxiv.org/abs/2011.12948) | 2021 | <details><summary>read why</summary>Photorealistically reconstructing deformable scenes using photos/videos captured casually from mobile phone</details> | [@orgoro](https://github.com/orgoro) | [zoom](https://us02web.zoom.us/rec/share/u2VA-FzTDv-X4CqUFUgxTDCTQbtQZD4Lik-AzsX7Eiy2ZAFhIukT3XgDr287v3vL.ejEfmDwh3H1D6l0g) (8Z3LeB^Q) | [slides](https://docs.google.com/presentation/d/1mz8tGLIPn6eJwlIcgjCu4wHQUUtRkD7hODBCdllVUKQ/edit?usp=sharing) |
| Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction |[Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction](https://arxiv.org/abs/2012.03065) | 2020 | <details><summary>read why</summary> Dynamic neural radiance fields for modeling the appearance and dynamics of a human face</details> | [@ganitk](https://github.com/ganitk) | [zoom](https://us02web.zoom.us/rec/share/G42wbJqJftDubhnzsBvhYXLL0GN3CbF9XwDcD-XL1o29n-4OE8wqf7qTFgaaraas.waXvnsGRs0uAY0bJ) (CJ+7=!U#) | [slides](https://docs.google.com/presentation/d/1oRcRRsTPOse1Ea0nhNJaY7SvbphntrfMdA6pI11ndRE/edit#slide=id.gfe17bd3166_0_21) |
| Animatable Neural Radiance Fields from Monocular RGB Videos|[Animatable Neural Radiance Fields from Monocular RGB Videos](https://arxiv.org/abs/2106.13629) | 2021 | <details><summary>read why</summary>Creating full body avatars using NERF</details> | [@alon.mengi](https://github.com/alon-mengi) | [zoom](https://us02web.zoom.us/rec/share/2LZMVdj7hbMs-MvhMdvAaQlSoTe2sgQHvIn6vtG9Y-LfNKAhi8XufxVc8KwZGFb-.wT1VWaVN-ZG2LreG) (Spc7+aYX) | [slides](https://docs.google.com/presentation/d/1gqP8v0kmZsWulJo0kAeTWLrnVBO3gPy4kaUGo2FKyeE/edit?usp=sharing) |
| I M Avatar: Implicit Morphable Head Avatars from Videos |[I M Avatar: Implicit Morphable Head Avatars from Videos](https://arxiv.org/abs/2112.07471) | 2022 | <details><summary>read why</summary>Creating an high resolution vavatar only from a cell phone video</details> | [@amitay.nachmani](https://github.com/amitay.nachmani) | [zoom](https://us02web.zoom.us/rec/share/UBUJIN_7LlIKuaDPDFvdUTehIDCiuVF2bYYAsbppy6tuxaLrw_jPZ4UzOZ3CnS_-.Vi36V2BGrdFxc1KD) (*dp9$&%R) | [slides](https://docs.google.com/presentation/d/1aKaDPCYzfHN9eqzEnRb2V9E_JO9H2WeTrTUBUoNlPlE/edit?usp=sharing) |
| ReLU Fields: The Little Non-linearity That Could |[ReLU Fields: The Little Non-linearity That Could](https://arxiv.org/abs/2205.10824) | 2022 | <details><summary>read why</summary>what is the smallest change to grid-based representations that allows for retaining the high fidelity result of MLPs while enabling fast reconstruction and rendering times</details> | [@ShiraBaronn](https://github.com/ShiraBaronn) | [zoom](https://us02web.zoom.us/rec/share/Dozws8GAUbfQM7V2SGXPXhaWZsNtcBeMKEV-ARDd_8jSDSlZUB7UkKeGQYY1Bhg.Vad3i389Ys32wfl2) (=8D2Fk1P) | [slides](https://docs.google.com/presentation/d/1vfzRaBteZ3eK0fx8bwlCpLt8u0sfK7jSJ69gNBBBBKQ/edit?usp=sharing) |
